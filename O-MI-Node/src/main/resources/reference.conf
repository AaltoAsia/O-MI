# Default settings for O-MI Node


# O-MI Node specific settings
omi-service {

  # Determines which database implementation is used for historical data: Slick, InfluxDB or None. (Warp10 requires a separate release)
  # Setting to "none" will only disable historical data queries (O-MI read parameters: begin, end, newest, oldest),
  # O-DF hierarchy, including all metadata and one newest value, and subscriptions are stored in separate journaling database.
  database = "slick"
  #database = "none"

  # Network interface (ip or hostname) to bind
  # the Open Messaging Interface and other HTTP services
  # O-MI Node accepts HTTP requests only for this address.
  # Use `"0.0.0.0"` for binding to all interfaces.
  interface = "0.0.0.0"

  ports = {
    # Port for all http traffic including O-MI, developer webclient and some other html pages
    webclient = 8080

    # TCP port to bind the administrator CLI, which listens ascii commands seperated by a linefeed
    cli = 8180

    # Used only if enabled with ExternalAgentListener Agent
    external-agents = 8181
  }

  # Timeout for starting the node, can be long if snapshot is not made for a while
  start-timeout = 5 minutes

  # Web sockets use Akka SourceQueue that buffers responses to be sent. If queue
  # has overflowed, web socket connection fails and is disconnected.
  websocket-queue-size = 100

  # Minimum supported interval for subscriptions
  min-subscription-interval = 1 seconds
  
  # How long to keep trying to send responses in case of infinite interval/duration. 
  # (Responses are essentially kept in memory so be careful about running out of memory.)
  callback-timeout = 20 seconds
  # Time to wait after failed callback, berofe a retry
  callback-delay    = 5 seconds

  # Allow callbacks only to addresses where the original request was sent.
  # In the future, could ask authorization plugins and also allow admin
  callback-authorization-enabled = false
  # List of admins to use if callback authorization is enabled
  admins = []


  # The minimum number of values the node will keep in database per InfoItem
  # This feature trims extra values periodically. It is inteded as simple way to limit historical data in test setups.
  num-latest-values-stored = 50
  # How often to trim excess values from database default 120 seconds
  trim-interval = 2 minutes


  # Journal DB Settings; Stores the O-DF structure with one latest value and subscriptions
  # Default timeout for journal queries when request ttl is not available
  journal-ask-timeout = 2 minutes
  # Snaphsots are used to speed up recovery of journal DBs after shutdown. They are also backups, in theory.
  # How often to take snapshot of the transaction journal default 10800 seconds
  snapshot-interval = 30 minutes
  # Snapshots that are older than given value are deleted when new timestamp is made, default 1 day.
  snapshot-delete-older = 3 day



  # O-DF path for saving some (read-only) public settings (num-latest-values-stored)
  settings-read-odfpath = "Objects/OMI-Service/Settings/"

  # These request types are allowed for everyone, without any authentication(!)
  # choices are: "write", "read", "cancel", "response", "call", "delete"
  # "response" is handled as a write request, but can be used to synchronize
  # results of a subscription directly as a callback receiver.
  # To configure a more fine tuned authorization, see other options below
  allowRequestTypesForAll = ["read", "cancel", "call"]

  # IP based authorization
  # What ip addresses are allowed to use O-MI Write and Response?
  # (Response for receiving a subscription.)
  # Static IP configuration for the listed IPs is recommended for security reasons.
  input-whitelist-ips=[
    "127.0.0.1",
    "0:0:0:0:0:0:0:1"
  ]

  # Allow a whole subnet for writing new data
  input-whitelist-subnets= [
        # Format:
        #<network ip>/<mask's length>
        #"127.0.0.0/8",
        #"0:0:0:0:0:0:0:0/48"
  ]

  # External authentication and authorization APIs, documented in /docs/AuthenticationAuthorization.md
  authAPI.v2 {
    # Set to true to enable, this authorization method is run last if others does not allow the request
    enable = false

    # Url to do authentication (checking if the consumer have valid credentials or session)
    # Can be left empty to disable and use only authorization service (below)
    authentication.url = ""
    # HTTP method to use, GET, POST, etc.
    authentication.method = "GET"

    # Url to do authorization (checking what data a given user has permissions to read or write)
    authorization.url = ""
    # HTTP method to use, GET, POST, etc.
    authorization.method = "POST"

    # (This is old setting, check `parameters` setting below for more control)
    # Copy these http headers from O-MI request to authentication headers
    authentication.copy-request-headers = []
    
    # Extract and use values from different places to define the requests
    parameters {
        # Constants can be defined here to be used as constant values in headers or other parameters
        initial {
            # variableName = value
            username = "" # to send empty username if username is not given by authentication
        }
        # Extract from o-mi request or the http request transfering it and put into variables
        fromRequest {
            # from omiEnvelope attributes
            # omiEnvelope {
                # attribute = variableName
                # token = "token"
            #}

            # from the Authorization header of http protocol
            #authorizationHeader {
                # type = variableName
                # Bearer = "token"
            #}

            # from other http headers
            #headers {
                # headerName = variableName
            #}

            # from query parameters of http URI
            #query {
                # queryParameterName = variableName

            #}
            #cookies {
                # cookieName = variableName
            #}
        }

        # Skips the authentication call if all of the following variables are missing or empty strings.
        # Can be used to allow nonauthenticated users to get some default
        # permissions from the Authorization service. e.g.
        # skipAuthenticationOnEmpty = ["token"]
        skipAuthenticationOnEmpty = [] 

        # put variables into authentication request (http GET)
        toAuthentication {
            #query {
              # parameterName = variableName  
              #token = "token"
            #}
            # authorizationHeader {}
            # headers {}
            # cookies {}
            # jsonbody {}
            # form-urlencoded {}
        }
        # extract parameters from Authentication response
        fromAuthentication {
            # same as above + jsonbody property search
            #jsonbody {
                # searchWord = variableName
                #email = "username"
                #isAdmin = "isadmin"
            #}

        }

        # predefined variables: requestType and requestTypeChar which tell O-MI verb name (r,w,c,d or read, write, call, delete)
        # for O-MI Authorization ref. impl: http POST {"username": <username>, "request": <first-letter-of-omi-request-type>}
        toAuthorization {
            #jsonbody {
                # jsonproperty = variableName
                #username = "username"
                #request = "requestTypeChar"
            #}
        }
     }
  }

  # Old external authorization API
  authAPI.v1 {
    # set true to enable authorization service
    enable-external-authorization-service = false
    authorization-service-port = 8088
    use-https = false
  }

  # Federation login based authorization (SAML)
  # Currently supports a list of EduPersonPrincipalNames
  # These users will have permission for full O-MI write access.
  #
  # Setup needed for this to work:
  #   This server should be behind reverse proxy that has also Shibboleth or other SAML product
  #   that adds HTTP_EPPN http header to the requests. HTTP_EPPN header should
  #   contain the name as written in the list below. The header should be secured from the user to forge it.
  # For Apache that would need:
  # <Location />
  #     AuthType shibboleth
  #     require shibboleth
  #     ShibUseHeaders On
  # </Location>
  input-whitelist-users = [
    # WARNING: Adding some values here can create a security issue if
    #          failing to setup this system correctly as described above.
    # Format (eppn): "user@organization"
  ]

  # Enable Kamon for monitoring o-mi node.
  # Reports to InfluxDB.
  kamon-enabled = false

  # Network interface and bort to bind the TCP external agent O-DF interface
  # Should be restricted to localhost or LAN ip for better security.
  external-agent-interface = "localhost"  # localhost means only loopback interface, blocks

}


# http configuration if run as a standalone server
# http://doc.akka.io/docs/akka/2.4.7/scala/http/configuration.html
akka.http {
  server {
    # Increase timeouts if running on low resources or very large requests
    request-timeout = 60 s
    
    idle-timeout = 60 s
    
    # This is required if IpAuthorization is used
    remote-address-header = on
    
    # maximun size of incoming messages
    parsing.max-content-length = 10 MiB
  }
  client {
    # Increase timeouts if running on low resources or very large requests
    idle-timeout = 60 s
  }

}

# http configuration if run as a servlet
# TODO: servlet not yet supported, file paths are wrong

#akka.http.servlet {
#    # Increase timeouts if running on low resources
#    request-timeout = 30 s
#
#    # This is required if IpAuthorization is used
#    remote-address-header = on
#
#    # Entry point for servlet, shouldn't be changed
#    boot-class = "http.ServletBoot"
#}


# Agent system defines Internal Java agents that are started during startup 
agent-system {

  # Agents to be started on startup,
  # their code should be compiled to jar file and found in 'deploy/' directory or in O-MI Node classpath
  internal-agents = [
    #{
    #  name = "DemoAgent" 
    #  class = "agents.ResponsibleJavaAgentDemo"
    #  language = "java"
    #  responsible = {
    #    "Objects/Service/Greeter" = "c"
    #  }
    #}
    #{
    #  name = "ParkingAgent" 
    #  class = "agents.parking.ParkingAgent"
    #  language = "scala"
    #  responsible = {
    #    "Objects/ParkingService" = "w"
    #    "Objects/ParkingService/FindParking" = "wc"
    #  }
    #  servicePath = "Objects/ParkingService"
    #  parkingFacilitiesPath = "Objects/ParkingService/ParkingFacilities"
    #  initialStateFile = "./conf/ParkingServiceOdf.xml"
    #  calculate-capacities = true
    #}
    # Writes random generated values to target path on every interval.
    # Test this agent if you are developing your own agents.
    #{
    #  name = "JavaAgent" 
    #  class = "agents.JavaAgent"
    #  language = "java"
    #  path = "Objects/JavaAgent/sensor"
    #  interval = 60 seconds
    #},
    #{
    #  name = "ResponsibleJavaAgent" 
    #  class = "agents.ResponsibleJavaAgent"
    #  language = "java"
    #   responsible = {
    #     "Objects/ResponsibleJavaAgent/" = "w"
    #   }
    #  path = "Objects/ResponsibleJavaAgent/sensor"
    #  interval = 60 seconds
    #},
    #{
    #  name = "ResponsibleScalaAgent" 
    #  class = "agents.ResponsibleScalaAgent"
    #  language = "scala"
    #   responsible = {
    #     "Objects/ResponsibleScalaAgent/" = "w"
    #   }
    #  path = "Objects/ResponsibleScalaAgent/sensor"
    #  interval = 60 seconds
    #},
    #{
    #  name = "ScalaAgent" 
    #  class = "agents.ScalaAgent"
    #  language = "scala"
    #  path = "Objects/ScalaAgent/sensor"
    #  interval = 60 seconds
    #},
    # # Reads O-DF structure from a file and
    # # writes random generated values to it on every interval.
    #{
    #   name = "SmartHouse"
    #   class = "agents.ODFAgent"
    #   language = "scala"
    #   file = "./conf/SmartHouse.xml"
    #   interval = 60 seconds
    #},

    # This agent opens a TCP port to listen to O-DF messages and writes the data to server as received.
    #{
    #    name = "ExternalAgentListener" 
    #    class = "agents.ExternalAgentListener"
    #    language = "scala"
    #    timeout = 10 seconds
    #    port = 8112
    #    interface = "localhost"
    #}
  ]

  # Time how long an actor has to at least run before trying
  # to restart in case of ThreadException
  starting-timeout = 60 seconds

}









# akka configuration http://doc.akka.io/docs/akka/2.3.9/general/configuration.html
akka {
  # Logging settings
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  logging-filter =  "akka.event.slf4j.Slf4jLoggingFilter"
  loglevel = DEBUG
  stdout-loglevel = DEBUG
  log-dead-letters-during-shutdown = off
  jvm-exit-on-fatal-error = off

}



# akka http configuration if run as a standalone server
# http://doc.akka.io/docs/akka/2.4.7/scala/http/configuration.html
akka.http.server {
  # Increase timeouts if running on low resources
  request-timeout = 60 s

  # This is required if IpAuthorization is used
  remote-address-header = on

  # maximun size of incoming messages
  parsing.max-content-length = 10 MiB
}

# http configuration if run as a servlet
# TODO: servlet not yet supported, file paths are wrong
#akka.http.servlet {
#    # Increase timeouts if running on low resources
#    request-timeout = 30 s
#
#    # This is required if IpAuthorization is used
#    remote-address-header = on
#
#    # Entry point for servlet, shouldn't be changed
#    boot-class = "http.ServletBoot"
#}

# HTTP CORS Settings
akka-http-cors {

    # When set, the amount of seconds the browser is allowed to cache the results of a preflight request.
    # This value is returned as part of the `Access-Control-Max-Age` preflight response header.
    # If `null`, the header is not added to the preflight response.
    max-age = 3 days
}








# Settings for input data pushing
bounded-mailbox {

  # Type of queue used for waiting write requests (also from internal agents)
  # Use "akka.dispatch.BoundedMailbox" for slowing agents with blocking if queue is full
  # Use "akka.dispatch.NonBlockingBoundedMailbox" for discarding write requests if queue is full
  # Use "akka.dispatch.UnBoundedMailbox" for max ram memory limited queue, crashing the server if queue is full
  mailbox-type = "akka.dispatch.BoundedMailbox"

  # Limit for queue
  mailbox-capacity = 1000

  # max push wait time if capacity limit is reached
  mailbox-push-timeout-time = 10s
}

# Set mailbox for input data pushing, shouldn't need to be changed
akka.actor.mailbox.requirements {
  "akka.dispatch.BoundedMessageQueueSemantics" = bounded-mailbox
}


# Value history database settings
#
#H2 database config below, change this section for other Slick supported SQL databases
slick-config {
  driver = "slick.driver.H2Driver$"
  db {
    url = "jdbc:h2:file:./database/valuehistorydb/sensorDB.h2;LOCK_TIMEOUT=10000" # XXX: only logs directory has the right permissions
    driver = org.h2.Driver
    connectionPool = "HikariCP"
    keepAliveConnection = true
    connectionTimeout = 15s
  }
}

#postgresql database config below
#slick-config{
#  driver = "slick.driver.PostgresDriver$"
#  db {
#    url = "jdbc:postgresql:XXX"
#    driver = org.postgresql.Driver
#    user = XXX
#   password = XXX
#  }
#}

influxDB-config {
  database-name = "testingdb"
  address = "http://localhost:8086/"
  #user = <user name>
  #password = <user's password>

}
warp10-config {

  address = "http://127.0.0.1:8280/api/v0/"
  read-token = "YOUR-OWN-READ-TOKEN"
  write-token = "YOUR-OWN-WRITE-TOKEN"
}








# Journal DB Settings; Stores the O-DF structure with one latest value and subscriptions
journalDBs.write-to-disk = true

akka {
  
  # akka configuration http://doc.akka.io/docs/akka/2.3.9/general/configuration.html
  # Logging settings
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  logging-filter =  "akka.event.slf4j.Slf4jLoggingFilter"
  loglevel = DEBUG
  stdout-loglevel = DEBUG
  log-dead-letters-during-shutdown = off
  jvm-exit-on-fatal-error = off
  extensions = [akka.persistence.Persistence]
  
  #Uncomment this to use Redis snapshot plugin
  #snapshot.plugin = "akka-persistence-redis.snapshot"
  persistence {

    journal {

      # For in-memory journal uncomment settings below and comment the conflicting current settings
      
      #plugin = "akka.persistence.journal.inmem"
      #auto-start-journals = ["akka.persistence.journal.inmem"]
      
      plugin = "akka.persistence.journal.leveldb"
      auto-start-journals = ["akka.persistence.journal.leveldb"]
      #If want to use some community plugin for journal store change these.
      #Redis plugin is already in dependencies. Others need to be added and
      #compiled.
      #plugin = "akka-persistence-redis.journal"
      #auto-start-journals = ["akka-persistence-redis.journal"]
      leveldb.dir = "./database/journaldb/journal"

    }

    snapshot-store {
      plugin = "akka.persistence.snapshot-store.local"
      auto-start-snapshot-stores = ["akka.persistence.snapshot-store.local"]
      #If want to use some community plugin for snapshot store change these
      #Redis plugin is already in dependencies. Others need to be added and
      #compiled
      #plugin = "akka-persistence-redis.snapshot"
      #auto-start-snapshot-stores = ["akka-persistence-redis.snapshot"]
      local.dir = "./database/journaldb/snapshots"
    }

  }

  actor {
    serializers {
      journal = "database.journal.serialization.JournalProtoBufSerializer"
    }

    serialization-bindings {
      "database.journal.PAddPollData" = journal
      "database.journal.PAddSub" = journal
      "database.journal.PCallback" = journal
      "database.journal.PDescription" = journal
      "database.journal.PErasePath" = journal
      "database.journal.PEventSub" = journal
      "database.journal.PEventSubs" = journal
      "database.journal.PInfoItem" = journal
      "database.journal.PIntervalSub" = journal
      "database.journal.PMetaData" = journal
      "database.journal.PNewEventSub" = journal
      "database.journal.PNormalEventSub" = journal
      "database.journal.PObject" = journal
      "database.journal.PObjects" = journal
      "database.journal.PPathToData" = journal
      "database.journal.PPersistentNode" = journal
      "database.journal.PPersistentValue" = journal
      "database.journal.PPollData" = journal
      "database.journal.PPolledSub" = journal
      "database.journal.PPollEventSubscription" = journal
      "database.journal.PPollIntervalSub" = journal
      "database.journal.PPollIntervalSubscription" = journal
      "database.journal.PPollNewEventSub" = journal
      "database.journal.PPollNormalEventSub" = journal
      "database.journal.PPollSub" = journal
      "database.journal.PQlmid" = journal
      "database.journal.PRemoveEventSub" = journal
      "database.journal.PRemoveIntervalSub" = journal
      "database.journal.PRemovePollSub" = journal
      "database.journal.PRemovePollSubData" = journal
      "database.journal.PSubIds" = journal
      "database.journal.PSubStoreState" = journal
      "database.journal.PTimestamp" = journal
      "database.journal.PUnion" = journal
      "database.journal.PValueList" = journal
      "database.journal.PWriteLatest" = journal
    }
  }

}






# Settings to fine tune parallelism
#
#akka.actor.deployment {
#
#  /database-handler {
#    dispatcher = db-dispatcher
#  }
#
#  /request-handler {
#    dispatcher = rh-dispatcher
#  }
#  
#  /subscription-handler {
#    dispatcher = subs-dispatcher
#  }
#  
#  /agent-system {
#    dispatcher = as-dispatcher
#  }
#
#}
#
#as-dispatcher {
#  type = Dispatcher
#  executor = "fork-join-executor"
#  fork-join-executor {
#    parallelism-min = 2
#    parallelism-factor = 2
#    parallelism-max = 10
#  }
#  throughput = 1
#}
#rh-dispatcher {
#  type = Dispatcher
#  executor = "fork-join-executor"
#  fork-join-executor {
#    parallelism-min = 2
#    parallelism-factor = 2
#    parallelism-max = 10
#  }
#  throughput = 1
#}
#subs-dispatcher {
#  type = Dispatcher
#  executor = "fork-join-executor"
#  fork-join-executor {
#    parallelism-min = 2
#    parallelism-factor = 2
#    parallelism-max = 10
#  }
#  throughput = 1
#}
#db-dispatcher {
#  type = Dispatcher
#  executor = "fork-join-executor"
#  fork-join-executor {
#    parallelism-min = 2
#    parallelism-factor = 2
#    parallelism-max = 10
#  }
#  throughput = 1
#}






#Settings for kamon if used for monitoring o-mi node
#Reporter settings when using influxdb
kamon.influxdb {

    hostname = "127.0.0.1"
    port = 8086

    database = "o-mi-node-monitoring"

    percentiles = [50.0, 70.0, 90.0, 95.0, 99.0, 99.9]

    additional-tags {
      service = no
      host = no
      instance = no

      blacklisted-tags = []
    }
}

#Some basic filters for monitoring Akka
kamon.util.filters {
  "akka.tracked-actor" {
    includes = [ "**" ]
  }

  "akka.tracked-dispatcher" {
    includes = [ "**" ]
  }

  "akka.traced-actor" {
    includes = [ "**" ]
  }
}
